Afin de mener à bien l'objectif énoncé dans l'introduction, les robots doivent se comporter de manière intelligente, et le choix de la bonne action est crucial. Il est cependant délicat de définir une seule <<meilleure>> action. En effet, la rationalité d'un agent peut être difficile à mesurer. D'après \cite{AIBrique}:
\begin{quote}
  <<La rationalité n'est pas synonyme de perfection, la rationalité maximise la performance espérée tandis que la perfection maximise la performance réelle.>>
\end{quote}

De plus, dans un système multi-agents, un choix d'action peut s'avérer bénéfique pour un agent mais mauvais pour l'ensemble du groupe. C'est pourquoi il est préférable de concevoir les mesures de performance en fonction de ce que l'on souhaite obtenir dans l'environnement et non en fonction de la façon dont devrait se comporter un agent.

Pour prendre un point de vue plus <<haut niveau>> sur cette problématique, il est possible d'utiliser le concept de machine à état et de diagramme d'état pour décrire un comportement. L'agent commence dans un état initial et peut à partir de cet état accomplir un certain nombre d'actions qui l'amènent dans d'autres états, à partir desquels d'autres actions et transitions sont possibles, et ainsi de suite. Ceci définit l'espace des états du système, c'est à dire l'ensemble de tous les états accessibles par une séquence d'action à partir de l'état initial. Cet espace des états peut être vu comme un graphe ou les n\oe{}uds représentent les états et les branches les transitions. Il en découle la notion de chemin (et de coût associé) représentant une séquence d'états reliés par une séquence d'actions. Cette approche est utilisée dans la section \ref{sec:tree}.~\cite{foraging, AIBrique}

D'autre part, un agent reçoit des percepts par l'intermédiaire de ses capteurs. L'agent réagit alors en exerçant une action sur l'environnement grâce à ses effecteurs. Il est aussi possible de découper le comportement autour de ce cycle, et c'est ce qui est fait par ARGoS, nous y reviendrons longuement dans la suite.
\begin{figure}[htb]
\centering
\begin{tikzpicture}[node distance = 2cm,>=stealth, auto]
  \node[rect](envir){\textsc{Environnement}};
  \node[block, below of=envir, yshift=-5em, xshift=-10em](capteurs){Capteurs};
  \node[decision, right of=capteurs, xshift=2.5em](decision){Choix de l'action};
  \node[block, right of=decision, xshift=4.5em](actions){Effecteurs};
  \coordinate (decision') at ($(decision) + (0,1.7cm)$);
  \path [line] (capteurs)--(decision);
  \path [line] (decision)--(actions);
  \path [line] (capteurs|-envir.south)-- node[yshift=1em, xshift=-2em,style={rectangle,fill=white}]{Percepts} (capteurs.north);
  \path [line] (actions.north)-- node[yshift=1em, xshift=2em,style={rectangle,fill=white}]{Actions} (actions|-envir.south);
  \begin{scope}[on background layer]
  \node [draw=black, fill=green!20 ,fit= (actions) (decision) (decision') (capteurs)](agents){};
  \node [yshift=-1em] at (agents.north) {\textsc{Agents}};
  \end{scope}
\end{tikzpicture}
    \caption{Cycle d'interaction entre l'environnement et les agents}
\end{figure}
La description des différents capteurs et effecteurs des footbots, ainsi que celle de l'environnement et des outils utilisés pour le représenter est faite dans le chapitre suivant.
